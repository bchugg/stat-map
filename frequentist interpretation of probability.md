---
created: 2024-08-29
lastmod: 2024-10-26
---

The frequentists want to define probability in terms of the long-run frequency of events. What do we mean when we say that the probability of tossing a coin and it landing heads is 1/2? On the frequentist view, we mean that if we were to toss it a larger and larger number of times, then fraction of times it lands heads will converge to 1/2. 

The frequentist interpretation is typically contrasted with the [[Bayesian interpretation of probability]]. Frequentists yell at Bayesians for being subjectivists, and Bayesians yell at frequentists for not being able to assign probability to one off events. 

Frequentism also has its share of philosophical problems. As David Wallace points out in [The Emergent Multiverse](https://www.amazon.co.uk/Emergent-Multiverse-Quantum-According-Interpretation/dp/0198707541), it suffers from circularity. First, if we haven't flipped the coin an infinite number of times, who knows what will happen in the long run. Second, we know that you won't actually see a perfectly equally number of coin flips in a finite sample. So you need some notion of "a typical run of coin flips" or something, which already has a notion of probability baked in. 

Frequentism is sometimes associated with, or considered a subset of, empirical theories of probability. Other empirical theories include the [propensity theory of probability](https://en.wikipedia.org/wiki/Propensity_probability), proposed by CS Peirce and, separately, Karl Popper. 

Aside from frequentism and Bayesian, a third option is [[instrumentalist theory of probability|instrumentalism]]. 
