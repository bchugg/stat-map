Typically, [[confidence sequences]] are non-asymptotic objects. There's no "limit" in the statements, as there is with, say, [[confidence intervals]] that are constructed via the [[central limit theorem]]. 

Non-asymptotic results are useful, but typically require stronger assumptions. Eg sub-$\psi$ tail bounds (see [[sub-psi process]]) or known bounded moments. Asymptotic results usually require weaker assumptions. Eg [[Wald interval]]'s based on the [[central limit theorem]] only requires finite variance. 

In fact, [Bahadur and Savage](https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-27/issue-4/The-Nonexistence-of-Certain-Statistical-Procedures-in-Nonparametric-Problems/10.1214/aoms/1177728077.full) show that if all you have is finite variance (without a known bound on this variance) then you cannot do non-asymptotic inference. 

