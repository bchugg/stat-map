---
created: 2024-09-02
lastmod: 2024-09-24
---

The law of likelihood says that any reasonable answer to the question "When is hypothesis A more likely than hypothesis B" (see [[Royall's three questions]]) must be answered in terms of the likelihood ratio. 

In particular, if $P_A. P_B$ are the distributions posited by hypothesis $A$ and $B$ respectively, then we have more evidence for $A$ precisely when the likelihood ratio $\d P_A / \d P_B$ is greater than one, and the magnitude of the likelihood measures the strength of that evidence. 

As stated by Hacking and Royall (for discrete spaces): 

> _Law of likelihood:_ If hypothesis A implies that the probability that a random variable $X$ takes the value $x$ is $p_A(x)$, while hypothesis $B$ implies that the probability is $p_B(x)$ then the observation $X=x$ is evidence supporting $A$ over $B$ if and only if $p_A(x)>p_B(x)$, and the likelihood ratio, $p_A(x)/p_B(x)$ measures the strength of that evidence

See Royall's book [Statistical Evidence: A Likelihood Paradigm](https://www.routledge.com/Statistical-Evidence-A-Likelihood-Paradigm/Royall/p/book/9781032478005?srsltid=AfmBOorIWGa9y5dcb0lInGHTpUWF6_fb4m0Es5PDuLTuPeh4L_83taMk). 

The law of likelihood is stronger than the [[likelihood principle]]. 